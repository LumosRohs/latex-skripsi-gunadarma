\chapter*{LAMPIRAN}

\setcounter{page}{1}
\renewcommand{\thepage}{L-\arabic{page}}

\noindent
\textbf{Listing Program}
\begin{enumerate}[label=\alph*.]
    \item Import Library
\end{enumerate}

\begin{lstlisting}[style=customc]
import os
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from random import sample
import matplotlib.pyplot as plt
import numpy as np
import cv2
import splitfolders
from tensorflow.keras.applications import EfficientNetV2S
from keras.layers import Input
from keras import layers
from tensorflow.keras.callbacks import ModelCheckpoint, 
ReduceLROnPlateau
import time
from tensorflow.keras.applications.efficientnet_v2 
import preprocess_input
from sklearn.metrics import accuracy_score, 
classification_report, confusion_matrix, 
ConfusionMatrixDisplay
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=2]
    \item Data Preparation
\end{enumerate}

\begin{lstlisting}[style=customc]
# Split Data
splitfolders.ratio('/content/dataset', output="split_images", 
seed=1337, ratio=(.8,.2))
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Define train and val dataset
base_dir = '/content/split_images'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Define class names and n of classes
class_names = sorted(
os.listdir('/content/split_images/train'))
n_classes = len(class_names)

# Print
print("No. Classes : {}".format(n_classes))
print("Classes     : {}".format(class_names))
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=3]
    \item Data Preprocessing
\end{enumerate}

\begin{lstlisting}[style=customc]
# Normalization and Augmentation
batch_size = 16

train_datagen = ImageDataGenerator(
                    preprocessing_function=preprocess_input,
                    rotation_range = 40,
                    shear_range = 0.2,
                    zoom_range = 0.2,
                    horizontal_flip = True,
                    vertical_flip = True)

val_datagen = ImageDataGenerator(
                    preprocessing_function=preprocess_input)


train_dataset = train_datagen.flow_from_directory(
        train_dir,
        shuffle=True,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical')

val_dataset = val_datagen.flow_from_directory(
        val_dir,
        shuffle=False,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical')
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=4]
    \item Pembuatan Model Transfer Learning EfficientNetV2
\end{enumerate}

\begin{lstlisting}[style=customc]
# Initialize EfficientNetV2 with imagenet weights
pre_trained_model = EfficientNetV2S(weights='imagenet', 
include_top=False, input_tensor=Input(shape=(224, 224, 3)))
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Freeze all layers
pre_trained_model.trainable = False
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Fine-tune model
x = pre_trained_model.output
x = layers.GlobalAveragePooling2D()(x)
outputs = layers.Dense(n_classes, activation='softmax')(x)

model = tf.keras.models.Model(
pre_trained_model.input, outputs)

model.summary()
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=5]
    \item Pelatihan Model
\end{enumerate}

\begin{lstlisting}[style=customc]
# Compile model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Callback checkpointer
checkpointer = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_loss',
    verbose=1,
    save_best_only=True,
    mode='min'
)
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Train
num_epochs = 50
start_time = time.time()

history = model.fit(train_dataset,
                epochs=num_epochs,
                validation_data=val_dataset,
                callbacks=[checkpointer]
                )

elapsed_time = time.time() - start_time
time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=6]
    \item Evaluasi Model
\end{enumerate}

\begin{lstlisting}[style=customc]
# Visualisasi Pelatihan
def report_train(history):
    # loss
    plt.plot(history.history['loss'],label='train loss')
    plt.plot(history.history['val_loss'],label='val loss')
    plt.legend()
    plt.show()
    # accuracies
    plt.plot(history.history['accuracy'],label='train acc')
    plt.plot(history.history['val_accuracy'],label='val acc')
    plt.legend()
    plt.show()

report_train(history)
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Classification Report and Confussion Matrix
def report_test(test_set,model=model):

    # evaluating test
    model.evaluate(test_set,batch_size=32)
    y_pred=model.predict(test_set)
    y_pred=np.argmax(y_pred,axis=1)
    accuracy_score(y_pred,test_set.classes)
    print(classification_report(y_pred,test_set.classes))

    # confusion_matrix
    labels = [i for i in train_dataset.class_indices]
    cm =confusion_matrix(y_pred, test_set.classes)
    disp = ConfusionMatrixDisplay(cm,display_labels=labels)
    disp.plot(cmap='Blues',xticks_rotation='vertical')
    plt.show()

report_test(val_dataset)
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Classification Report and Confussion Matrix best model
from tensorflow.keras.models import load_model
best_model = load_model('best_model.h5')
report_test(val_dataset, best_model)
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=7]
    \item Visualisasi Grad-CAM
\end{enumerate}

\begin{lstlisting}[style=customc]
# Grad-CAM heatmap
def get_gradcam_heatmap(model, img_array, 
last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model(
        [model.inputs], 
        [model.get_layer(last_conv_layer_name).output, 
        model.output]
    )

    with tf.GradientTape() as tape:
        conv_layer_output, 
        predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_layer_output = conv_layer_output[0]
    heatmap = conv_layer_output @ 
    pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    heatmap = tf.maximum(heatmap, 0) / 
    tf.math.reduce_max(heatmap)
    heatmap = heatmap.numpy()
    return heatmap
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Display Grad-CAM with labels
def display_gradcam_with_labels(img_path, 
heatmap, real_label, predicted_label, alpha=0.4):
    img = cv2.imread(img_path)
    heatmap = cv2.resize(heatmap, 
    (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(
    heatmap, cv2.COLORMAP_JET)
    superimposed_img = cv2.addWeighted(
    img, alpha, heatmap, 1 - alpha, 0)

    plt.figure(figsize=(10, 10))
    plt.subplot(1, 2, 1)
    plt.title(f'Original Image\nReal: {real_label}')
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title(f'Grad-CAM\nPredicted: {predicted_label}')
    plt.imshow(cv2.cvtColor(
    superimposed_img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Menampilkan hasil visualisasi Grad-CAM
images_labels = [
    ('/content/split_images/val/ayam bakar/ayam bakar.jpg', 
    'ayam bakar'),
    ('/content/split_images/val/bakso/pic_007.jpg', 
    'bakso'),
    ('/content/split_images/val/gado_gado/pic_007.jpg', 
    'gado-gado'),
    ('/content/split_images/val/gudeg/gudeg_009.jpg', 
    'gudeg'),
    ('/content/split_images/val/nasi_goreng/nasi_goreng.jpg', 
    'nasi goreng'),
    ('/content/split_images/val/pempek/pempek_007.jpg', 
    'pempek'),
    ('/content/split_images/val/rawon/rawon_007.jpg', 
    'rawon'),
    ('/content/split_images/val/rendang/pic_007.jpg', 
    'rendang'),
    ('/content/split_images/val/sate/pic_007.jpg', 
    'sate'),
    ('/content/split_images/val/soto/soto_007.jpg', 
    'soto'),
]

for img_path, real_label in images_labels:
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    preds = best_model.predict(img_array)
    predicted_label = class_names[np.argmax(preds)]

    heatmap = get_gradcam_heatmap(
    best_model, img_array, 'top_conv')
    display_gradcam_with_labels(
    img_path, heatmap, real_label, predicted_label)
\end{lstlisting}

\begin{enumerate}[label=\alph*., start=8]
    \item Pengujian Model menggunakan data nutrisi makanan
\end{enumerate}

\begin{lstlisting}[style=customc]
# Membaca file xlsx
data = pd.read_excel('/content/nutrisi.xlsx')
data
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Fungsi untuk menampilkan data nutrisi makanan
def predict_class_with_nutrition(model, images, show = True):
  for img in images:
    img = image.load_img(img, target_size=(224, 224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)

    preds = model.predict(img)
    class_labels = class_names
    pred = np.argmax(preds, axis=-1)
    predicted_class = class_names[pred[0]]
    predicted_prob = preds[0][pred[0]] * 100

    nutrition = data[data['nama makanan'].str.contains(
    predicted_class, case=False)]
    nutrition = nutrition.iloc[:, 1:]
    print("-" * 30)
    for col in nutrition.columns:
      print(f"{col.capitalize():>20}: 
      {nutrition[col].iloc[0]:}")
    print("-" * 30)

    if show:
        plt.imshow(img[0].astype('uint8'))
        plt.axis('off')
        plt.title(f"{predicted_class} 
        ({predicted_prob:.2f}%)")
        plt.show()
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Percobaan dengan data ayam bakar
images = []
images.append(
'/content/split_images/val/ayam bakar/ayam bakar (102).jpg') 

predict_class_with_nutrition(best_model, images)
\end{lstlisting}

\begin{lstlisting}[style=customc]
# Percobaan dengan data ayam
images = []
images.append('/content/split_images/val/sate/pic_007.jpg')

predict_class_with_nutrition(best_model, images)
\end{lstlisting}











